03/19/2025 21:22:31 - INFO - __main__ - ***** Training arguments *****
03/19/2025 21:22:31 - INFO - __main__ - Namespace(config='configs/ddpm.yaml', data_dir='../imagenet100_128x128/train', image_size=128, batch_size=32, num_workers=5, num_classes=100, run_name='exp-4-ddpm', output_dir='experiments', num_epochs=5, learning_rate=0.0001, weight_decay=1e-05, grad_clip=1.0, seed=42, mixed_precision='none', num_train_timesteps=1000, num_inference_steps=100, beta_start=0.0001, beta_end=0.02, beta_schedule='linear', variance_type='fixed_small', prediction_type='epsilon', clip_sample=True, clip_sample_range=1.0, unet_in_size=128, unet_in_ch=3, unet_ch=128, unet_ch_mult=[1, 2, 2, 4], unet_attn=[2, 3], unet_num_res_blocks=2, unet_dropout=0.0, latent_ddpm=False, use_cfg=False, cfg_guidance_scale=2.0, use_ddim=False, ckpt=None, max_train_steps=20310, distributed=False, world_size=1, rank=0, local_rank=0, device='cuda', total_batch_size=32)
03/19/2025 21:22:31 - INFO - __main__ - ***** Running training *****
03/19/2025 21:22:31 - INFO - __main__ -   Num examples = 130000
03/19/2025 21:22:31 - INFO - __main__ -   Num Epochs = 5
03/19/2025 21:22:31 - INFO - __main__ -   Instantaneous batch size per device = 32
03/19/2025 21:22:31 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 32
03/19/2025 21:22:31 - INFO - __main__ -   Total optimization steps per epoch 4062
03/19/2025 21:22:31 - INFO - __main__ -   Total optimization steps = 20310
  0%|                                                       | 0/20310 [00:00<?, ?it/s]03/19/2025 21:22:31 - INFO - __main__ - Epoch 1/5
  0%|                                             | 1/20310 [00:01<9:27:58,  1.68s/it]03/19/2025 21:22:33 - INFO - __main__ - Epoch 1/5, Step 0/4062, Loss 0.9970714449882507 (0.9970714449882507)
  0%|▏                                           | 91/20310 [01:40<6:10:48,  1.10s/it]Traceback (most recent call last):
  File "/jet/home/yzhou17/hw5/hw5_student_starter_code/train.py", line 438, in <module>
    main()
  File "/jet/home/yzhou17/hw5/hw5_student_starter_code/train.py", line 364, in main
    model_pred = unet(noisy_images, timesteps, class_emb)
  File "/jet/home/yzhou17/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/jet/home/yzhou17/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/jet/home/yzhou17/hw5/hw5_student_starter_code/models/unet.py", line 84, in forward
    h = layer(h, temb, c)
  File "/jet/home/yzhou17/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/jet/home/yzhou17/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/jet/home/yzhou17/hw5/hw5_student_starter_code/models/unet_modules.py", line 206, in forward
    h = self.block1(x)
  File "/jet/home/yzhou17/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/jet/home/yzhou17/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/jet/home/yzhou17/.local/lib/python3.10/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/jet/home/yzhou17/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/jet/home/yzhou17/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/jet/home/yzhou17/.local/lib/python3.10/site-packages/torch/nn/modules/normalization.py", line 313, in forward
    return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)
  File "/jet/home/yzhou17/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 2965, in group_norm
    return torch.group_norm(
KeyboardInterrupt
